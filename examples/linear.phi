# TODO: formula user-defined DSL
#netInput    :: formula { Σ[i in |inputs|] (inputs[i] × weights[i]) }
#meanSqError :: formula { 0.5 Σ[o in |outputs|] (targets[o] - outputs[o])² }

netInput :: func(inputs: []float, weights: []float) -> float {
  result := 0.0;
  for input, index in inputs:
    # TODO: add and assign operator
    #result += input * weights[index];
    result = result + input * weights[index];
  return result;
}

#- TODO: dynamic arrays [..]
linear_node :: struct {
  output: float;
  weights: [..]float;
}

linear_network :: struct {
  learningRate: float;
  outputs: [..]linear_node;
}
-#

linear_node :: struct {
  bias: float;
  biasDelta: float;
  weights: [1]float;
  weightDeltas: [1]float;
}

# a linear neural network with online learning
#
# useful for calculating a linear regression in an "online" environment,
# like from a stream of application events
linear_network :: struct {
  learningRate: float;
  outputs: [1]linear_node;
}

trainLinear :: func(net: ^linear_network, inputs: [1]float, outputs: [1]float) {
  for ^node, index in net.outputs {
    # TODO: keyword arguments
    #node.output = netInput(inputs=inputs, weights=node.weights);
    node.output = netInput(inputs, node.weights);
    target := outputs[index];
    error := target - node.output;

    node.biasDelta = node.biasDelta + error;
    node.bias = node.bias + (node.biasDelta * net.learningRate);
    for weight, index in node.weightDeltas {
      weightDelta := node.weightDeltas[index] + (error * inputs[index]);
      node.weights[index] = weight + (weightDelta * net.learningRate);
      node.weightDeltas[index] = weightDelta;
    }
  }
}

main :: () {
  neuralNet : linear_network;
  for example in examples:
    trainLinear(neuralNet, example.inputs, example.outputs);
}
